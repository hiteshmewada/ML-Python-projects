{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05565661-82fa-45bd-8851-2af4c028731d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapipe in c:\\python39\\lib\\site-packages (0.8.9)\n",
      "Requirement already satisfied: opencv-python in c:\\python39\\lib\\site-packages (4.5.4.58)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ip (c:\\python39\\lib\\site-packages)\n",
      "WARNING: You are using pip version 21.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the 'C:\\Python39\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\python39\\lib\\site-packages (from mediapipe) (1.21.3)\n",
      "Requirement already satisfied: opencv-contrib-python in c:\\python39\\lib\\site-packages (from mediapipe) (4.5.4.58)\n",
      "Requirement already satisfied: absl-py in c:\\python39\\lib\\site-packages (from mediapipe) (1.0.0)\n",
      "Requirement already satisfied: protobuf>=3.11.4 in c:\\python39\\lib\\site-packages (from mediapipe) (3.19.1)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\python39\\lib\\site-packages (from mediapipe) (21.2.0)\n",
      "Requirement already satisfied: six in c:\\python39\\lib\\site-packages (from mediapipe) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in c:\\python39\\lib\\site-packages (from mediapipe) (3.4.3)\n",
      "Requirement already satisfied: wheel in c:\\python39\\lib\\site-packages (from mediapipe) (0.37.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\python39\\lib\\site-packages (from matplotlib->mediapipe) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\python39\\lib\\site-packages (from matplotlib->mediapipe) (8.4.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\python39\\lib\\site-packages (from matplotlib->mediapipe) (1.3.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\python39\\lib\\site-packages (from matplotlib->mediapipe) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python39\\lib\\site-packages (from matplotlib->mediapipe) (0.10.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapipe opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "08e3f2e8-c7b9-4d50-ab05-9eb9e457a6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 #OpenCV-Python is a library of Python bindings designed to solve computer vision problems\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "mp_drawing=mp.solutions.drawing_utils\n",
    "mp_pose=mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dde94988-81de-4079-a2a9-2a8b9f8a344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VIDEO FEED\n",
    "cap=cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret,frame=cap.read()\n",
    "    cv2.imshow('Mediapipe Feed',frame)\n",
    "    if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1e9353d-8a5a-4b89-9e54-527b2f868be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "# setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5,min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret,frame=cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image=cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable=False\n",
    "        \n",
    "        # Make detection\n",
    "        results=pose.process(image)\n",
    "        \n",
    "        # Recolor image to BGR\n",
    "        image.flags.writeable=True\n",
    "        image=cv2.cvtColor(frame,cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image,results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(200,117,66), thickness=2, circle_radius=2),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed',image)\n",
    "        if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec4a6775-32f4-47e3-b2da-9bf022fdf72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "# setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5,min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret,frame=cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image=cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable=False\n",
    "        \n",
    "        # Make detection\n",
    "        results=pose.process(image)\n",
    "        \n",
    "        # Recolor image to BGR\n",
    "        image.flags.writeable=True\n",
    "        image=cv2.cvtColor(frame,cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks=results.pose_landmarks.landmark\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image,results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(200,117,66), thickness=2, circle_radius=2),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed',image)\n",
    "        if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c053bbe0-ee7e-45c5-ab1b-a6db34842369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6beb8bce-800d-4a79-9ae4-0ed03ea227a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PoseLandmark.NOSE\n",
      "PoseLandmark.LEFT_EYE_INNER\n",
      "PoseLandmark.LEFT_EYE\n",
      "PoseLandmark.LEFT_EYE_OUTER\n",
      "PoseLandmark.RIGHT_EYE_INNER\n",
      "PoseLandmark.RIGHT_EYE\n",
      "PoseLandmark.RIGHT_EYE_OUTER\n",
      "PoseLandmark.LEFT_EAR\n",
      "PoseLandmark.RIGHT_EAR\n",
      "PoseLandmark.MOUTH_LEFT\n",
      "PoseLandmark.MOUTH_RIGHT\n",
      "PoseLandmark.LEFT_SHOULDER\n",
      "PoseLandmark.RIGHT_SHOULDER\n",
      "PoseLandmark.LEFT_ELBOW\n",
      "PoseLandmark.RIGHT_ELBOW\n",
      "PoseLandmark.LEFT_WRIST\n",
      "PoseLandmark.RIGHT_WRIST\n",
      "PoseLandmark.LEFT_PINKY\n",
      "PoseLandmark.RIGHT_PINKY\n",
      "PoseLandmark.LEFT_INDEX\n",
      "PoseLandmark.RIGHT_INDEX\n",
      "PoseLandmark.LEFT_THUMB\n",
      "PoseLandmark.RIGHT_THUMB\n",
      "PoseLandmark.LEFT_HIP\n",
      "PoseLandmark.RIGHT_HIP\n",
      "PoseLandmark.LEFT_KNEE\n",
      "PoseLandmark.RIGHT_KNEE\n",
      "PoseLandmark.LEFT_ANKLE\n",
      "PoseLandmark.RIGHT_ANKLE\n",
      "PoseLandmark.LEFT_HEEL\n",
      "PoseLandmark.RIGHT_HEEL\n",
      "PoseLandmark.LEFT_FOOT_INDEX\n",
      "PoseLandmark.RIGHT_FOOT_INDEX\n"
     ]
    }
   ],
   "source": [
    "for lndmrk in mp_pose.PoseLandmark:\n",
    "    print(lndmrk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d939634-fe1e-4282-937a-31394eda812e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x: 0.6603877544403076\n",
       "y: 0.9679465889930725\n",
       "z: -0.3429199755191803\n",
       "visibility: 0.9965404272079468"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa75c3c7-386e-4414-99a6-9fec076fc856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PoseLandmark.LEFT_SHOULDER: 11>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mp_pose.PoseLandmark.LEFT_SHOULDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "092a96ef-ebf9-4857-aa35-fc463e3534b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mmp_drawing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDrawingSpec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcolor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mthickness\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcircle_radius\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m      DrawingSpec(color: Tuple[int, int, int] = (224, 224, 224), thickness: int = 2, circle_radius: int = 2)\n",
       "\u001b[1;31mSource:\u001b[0m        \n",
       "\u001b[1;33m@\u001b[0m\u001b[0mdataclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataclass\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;32mclass\u001b[0m \u001b[0mDrawingSpec\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m  \u001b[1;31m# Color for drawing the annotation. Default to the white color.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m  \u001b[0mcolor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mWHITE_COLOR\u001b[0m\u001b[1;33m\n",
       "\u001b[0m  \u001b[1;31m# Thickness for drawing the annotation. Default to 2 pixels.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m  \u001b[0mthickness\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\n",
       "\u001b[0m  \u001b[1;31m# Circle radius. Default to 2 pixels.\u001b[0m\u001b[1;33m\n",
       "\u001b[0m  \u001b[0mcircle_radius\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\python39\\lib\\site-packages\\mediapipe\\python\\solutions\\drawing_utils.py\n",
       "\u001b[1;31mType:\u001b[0m           type\n",
       "\u001b[1;31mSubclasses:\u001b[0m     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mp_drawing.DrawingSpec??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b8b121c2-e90e-4d85-a11b-c971216b6e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angle(a,b,c):\n",
    "    a=np.array(a) #first\n",
    "    b=np.array(b) #mid\n",
    "    c=np.array(c) #end\n",
    "    \n",
    "    #Arc tangent of two numbers, or four-quadrant inverse tangent.\n",
    "    radians=np.arctan2(c[1]-b[1],c[0]-b[0])-np.arctan2(a[1]-b[1],a[0]-b[0])\n",
    "    angle=np.abs(radians*180.0/np.pi)\n",
    "    \n",
    "    if angle>180.0:\n",
    "        angle=360-angle\n",
    "    \n",
    "    return angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b00f293-4213-44f1-97fb-821fd628b511",
   "metadata": {},
   "outputs": [],
   "source": [
    "shoulder=[landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,\n",
    "          landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "elbow=[landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,\n",
    "          landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "wrist=[landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,\n",
    "          landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03006f60-f6d2-4e51-8159-a01baa3dd755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.6603877544403076, 0.9679465889930725],\n",
       " [0.8554075956344604, 1.269587755203247],\n",
       " [0.899632453918457, 1.5147031545639038])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shoulder,elbow,wrist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d99386b1-6918-4c67-96b6-d47bf5ad5603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157.34368795201186"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_angle(shoulder,elbow,wrist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23ee72f6-eacb-461e-8df2-ce6a935dfcf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "# setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5,min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret,frame=cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image=cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable=False\n",
    "        \n",
    "        # Make detection\n",
    "        results=pose.process(image)\n",
    "        \n",
    "        # Recolor image to BGR\n",
    "        image.flags.writeable=True\n",
    "        image=cv2.cvtColor(frame,cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks=results.pose_landmarks.landmark\n",
    "            \n",
    "            # get co-ordinates\n",
    "            shoulder=[landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            elbow=[landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            wrist=[landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            \n",
    "            # calculate angle\n",
    "            angle=calculate_angle(shoulder,elbow,wrist)\n",
    "            \n",
    "            # visualize angle [640,480] == co-ordinates of video player\n",
    "            cv2.putText(image, str(angle),\n",
    "                        tuple(np.multiply(elbow,[640,480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),2,cv2.LINE_AA)\n",
    "            # font,size,color,line width ,line\n",
    "            # print(landmarks)\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image,results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(200,117,66), thickness=2, circle_radius=2),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed',image)\n",
    "        if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b8735ce9-f3fe-4021-920e-64133a39bb2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "9\n",
      "9\n",
      "10\n",
      "10\n",
      "11\n",
      "11\n",
      "12\n",
      "12\n",
      "13\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cap=cv2.VideoCapture(0)\n",
    "\n",
    "# curl counter variables for left\n",
    "counter=0\n",
    "stage=None\n",
    "\n",
    "# curl counter variables for right\n",
    "rcounter=0\n",
    "rstage=None\n",
    "\n",
    "# setup mediapipe instance\n",
    "with mp_pose.Pose(min_detection_confidence=0.5,min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret,frame=cap.read()\n",
    "        \n",
    "        # Recolor image to RGB\n",
    "        image=cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable=False\n",
    "        \n",
    "        # Make detection\n",
    "        results=pose.process(image)\n",
    "        \n",
    "        # Recolor image to BGR\n",
    "        image.flags.writeable=True\n",
    "        image=cv2.cvtColor(frame,cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Extract landmarks\n",
    "        try:\n",
    "            landmarks=results.pose_landmarks.landmark\n",
    "            \n",
    "            # get co-ordinates of left shoulder\n",
    "            shoulder=[landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]\n",
    "            elbow=[landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]\n",
    "            wrist=[landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]\n",
    "            \n",
    "            # get co-ordinates of right shoulder\n",
    "            rshoulder=[landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value].y]\n",
    "            relbow=[landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value].y]\n",
    "            rwrist=[landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].x,landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value].y]\n",
    "            \n",
    "            # calculate angle for left\n",
    "            angle=calculate_angle(shoulder,elbow,wrist)\n",
    "            \n",
    "             # calculate angle for right\n",
    "            rangle=calculate_angle(rshoulder,relbow,rwrist)\n",
    "            \n",
    "            # visualize angle [640,480] == co-ordinates of video player\n",
    "            cv2.putText(image, str(angle),\n",
    "                        tuple(np.multiply(elbow,[640,480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),2,cv2.LINE_AA)\n",
    "            cv2.putText(image, str(rangle),\n",
    "                        tuple(np.multiply(relbow,[640,480]).astype(int)),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX,0.5,(255,255,255),2,cv2.LINE_AA)\n",
    "            # font,size,color,line width ,line type\n",
    "            # print(landmarks)\n",
    "            \n",
    "            # curl counter logic for left\n",
    "            if angle> 160:\n",
    "                stage=\"DOWN\"\n",
    "            if angle<30 and stage=='DOWN':\n",
    "                stage=\"UP\"\n",
    "                counter+=1\n",
    "                print(counter)\n",
    "                \n",
    "                # curl counter logic for left\n",
    "            if rangle> 160:\n",
    "                rstage=\"DOWN\"\n",
    "            if rangle<30 and rstage=='DOWN':\n",
    "                rstage=\"UP\"\n",
    "                rcounter+=1\n",
    "                print(rcounter)\n",
    "                \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # setup status box for left\n",
    "        cv2.rectangle(image,(0,0),(300,100),(180,117,386),-1) # start pt,end pt,color,width\n",
    "        \n",
    "        # Rep data\n",
    "        cv2.putText(image,'For left hand',(15,12),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,0),1,cv2.LINE_AA)\n",
    "        cv2.putText(image,'REPS',(15,32),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,0),1,cv2.LINE_AA)\n",
    "        cv2.putText(image,str(counter),(10,90),cv2.FONT_HERSHEY_SIMPLEX,2,(255,255,255),2,cv2.LINE_AA)\n",
    "        \n",
    "        # Stage data\n",
    "        cv2.putText(image,'STAGE',(125,32),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,0),1,cv2.LINE_AA)\n",
    "        cv2.putText(image,stage,(120,90),cv2.FONT_HERSHEY_SIMPLEX,2,(255,255,255),2,cv2.LINE_AA)\n",
    "        \n",
    "        # setup status box for right\n",
    "        cv2.rectangle(image,(370,0),(700,100),(180,117,386),-1) # start pt,end pt,color,width\n",
    "        \n",
    "        # Rep data\n",
    "        cv2.putText(image,'For right hand',(445,12),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,0),1,cv2.LINE_AA)\n",
    "        cv2.putText(image,'REPS',(380,32),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,0),1,cv2.LINE_AA)\n",
    "        cv2.putText(image,str(rcounter),(380,90),cv2.FONT_HERSHEY_SIMPLEX,2,(255,255,255),2,cv2.LINE_AA)\n",
    "        \n",
    "        # Stage data\n",
    "        cv2.putText(image,'STAGE',(460,32),cv2.FONT_HERSHEY_SIMPLEX,0.5,(0,0,0),1,cv2.LINE_AA)\n",
    "        cv2.putText(image,rstage,(460,90),cv2.FONT_HERSHEY_SIMPLEX,2,(255,255,255),2,cv2.LINE_AA)\n",
    "        \n",
    "        # Render detections\n",
    "        mp_drawing.draw_landmarks(image,results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                 mp_drawing.DrawingSpec(color=(200,117,66), thickness=2, circle_radius=2),\n",
    "                                 mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)\n",
    "                                 )\n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed',image)\n",
    "        if cv2.waitKey(10) & 0xFF==ord('q'):\n",
    "            break\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b249dc-c5f5-40f9-96b4-7789f2179f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1008c4d-63a7-457d-8f25-95fc67a99239",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbe6d5b-df12-4030-be55-eddbb1bbce90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0f5403-e929-4d68-bcdb-6d1d6754638e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a9bd57-83a4-4a4c-a0ea-8af2769a1403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28108fc-6d81-4acc-9e87-cb64b440dd47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c878f61d-34f7-468b-bbc3-5c3b23e76dc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81ab575-cf6f-4c82-a9e0-58b7c2b0e9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7de7aa-45a8-427c-b648-dc505a96de1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3835d488-a1cf-43ec-bfb0-1015a27f896d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
